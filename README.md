# web_crawler  
> یک ابزار ماژولار برای خزیدن صفحات وب و استخراج داده‌ها  
> نسخهٔ فعلی: (مثلاً) v0.1.0

[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)]()  
[![License](https://img.shields.io/badge/license-MIT-green.svg)]()

## 📌 معرفی  
پروژهٔ **web_crawler** هدف دارد تا با ساختاری ماژولار به شما امکان دهد تا به‌راحتی صفحات وب را کاوش (crawl) کرده، داده‌ها را استخراج و مدیریت نمایید. این پروژه با تمرکز بر خوانایی، انعطاف‌پذیری، و قابلیت توسعه طراحی شده است.

ویژگی‌های کلیدی:  
- ساختار ماژولار (مثلاً `client/`, `server/`, `shared/`، یا هر ماژول دیگری)  
- امکان تعریف استراتژی‌های متعدد خزیدن  
- استخراج داده به شکل قابل پیکربندی  
- ذخیره‌سازی نتایج و مدیریت آن‌ها  
- قابل توسعه برای پروژه‌های واقعی

## ✅ قابلیت‌ها  
- ماژول‌های جداگانه برای کلاینت و سرور  
- استفاده از تنظیمات پیکربندی (config) برای کنترل رفتار خزنده  
- امکان گسترش آسان (مثلاً اضافه‌کردن ماژول‌های جدید)  
- استانداردسازی ساختار پروژه برای راحتی نگهداری  
- مستندسازی کامل (ازجمله این README) برای کمک به توسعه‌دهندگان

## 🧰 پیش‌نیازها  
قبل از شروع، مطمئن شوید که موارد زیر را دارید:  
- Python نسخه‌ی **3.10 یا بالاتر** (یا آن نسخه‌ای که در پروژه تعیین کرده‌اید)  
- نصب و راه‌اندازی uv به عنوان مدیر بسته و مدیریت محیط مجازی  
  - uv یک ابزار مدرن، سریع، جایگزین pip/venv/virtualenv است. :contentReference[oaicite:2]{index=2}  
  - می‌توانید آن را نصب کنید و برای ایجاد محیط مجازی و نصب کتابخانه‌ها استفاده نمایید. :contentReference[oaicite:3]{index=3}  
- دسترسی به اینترنت (برای دانلود بسته‌ها و اجرای خزنده)  
- (اختیاری) دسترسی به سرویس یا پایگاه داده اگر پروژه ذخیره‌سازی داده دارد

## 🚀 راه‌اندازی سریع  
در ادامه راهنمای گام‌به‌گام راه‌اندازی پروژه با استفاده از uv آمده است:

```bash
# ۱. کلون کردن مخزن
git clone https://github.com/hamed-py/web_crawler.git
cd web_crawler

# ۲. (اختیاری) نصب uv اگر هنوز نصب نشده
# با روش پیشنهادی:
curl -LsSf https://astral.sh/uv/install.sh | sh       # برای macOS/Linux
# یا روی ویندوز:
# powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
# (جزئیات بیشتر در مستندات uv) :contentReference[oaicite:4]{index=4}

#  ایجاد محیط مجازی و فعال‌سازی  
uv venv      
uv env activate  

#  نصب وابستگی‌ها  
# فرض بر این است که فایل lock یا requirements دارید
uv pip sync        
# یا اگر فقط requirements.txt دارید:
uv pip install -r requirements.txt

```

--------------------------------------------------------------------------------------------------------------------------------------------------------------
اجرای برنامه (استفاده از ۳ ترمینال)
برای اجرای کامل سیستم، شما باید ۳ ترمینال مجزا باز کنید. در هر سه ترمینال، ابتدا محیط مجازی (.venv) را طبق دستور بالا فعال کنید.

اطمینان حاصل کنید که سرویس‌های PostgreSQL و Redis شما روشن و در حال اجرا هستند.

🏁 ترمینال ۱: اجرای ARQ Worker
ورکر arq باید همیشه در پس‌زمینه در حال اجرا باشد تا وظایف جستجو را از صف Redis دریافت و پردازش کند.



# (محیط مجازی .venv فعال است)
# به arq بگویید که تنظیمات ورکر را از فایل server/worker.py (کلاس WorkerSettings) بخواند
uv run arq server.worker.WorkerSettings
خروجی مورد انتظار: پیامی مبنی بر اتصال موفقیت‌آمیز ورکر به Redis و آماده به کار بودن.

🏁 ترمینال ۲: اجرای FastAPI Server
سرور FastAPI مسئول مدیریت API و ارسال وظایف به صف است.


# (محیط مجازی .venv فعال است)
# اجرای سرور uvicorn با قابلیت reload (مناسب برای توسعه)
uv run uvicorn server.server:app --host 127.0.0.1 --port 8000 --reload
خروجی مورد انتظار: سرور اکنون روی آدرس http://127.0.0.1:8000 در دسترس است.

🏁 ترمینال ۳: اجرای کلاینت Tkinter
این ترمینال کلاینت گرافیکی را اجرا می‌کند. این کلاینت همچنین در اولین اجرا، جداول مورد نیاز در پایگاه داده را به‌صورت خودکار ایجاد می‌کند (به لطف تابع create_db_and_tables_sync).



# (محیط مجازی .venv فعال است)
uv run python client/main.py
خروجی مورد انتظار: پنجره "پنل مدیریت جستجوگر ویکی‌پدیا" باز خواهد شد.
